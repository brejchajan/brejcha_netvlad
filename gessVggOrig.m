% @Author: Jan Brejcha <ibrejcha>
% @Date:   2017-02-13T16:53:18+01:00
% @Email:  ibrejcha@fit.vutbr.cz, brejchaja@gmail.com
% @Project: Locate
% @Last modified by:   ibrejcha
% @Last modified time: 2017-02-14T11:01:12+01:00



% ---------- Tiny dummy training example

% This is just to see if you got all the dependencies and configurations set up correctly.
% Get a tiny version of the Tokyo Time Machine dataset from our research page ( www.di.ens.fr/willow/research/netvlad/ ) as well as the dataset specification. Point paths.dsetRootTokyoTM in localPaths.m to its location. Run the code below to train max pooling on top of AlexNet for this tiny dataset:

%dbTrain= dbTiny('train'); dbVal= dbTiny('val');
dbTrain= dbGESS('train'); dbVal= dbGESS('val');

trainWeakly(dbTrain, dbVal, ...
    'netID', 'netvlad', 'layerName', 'conv5_3', ...
    'method', 'vlad_preL2_intra', 'backPropToLayer', 'conv5_3', ...
    'margin', 0.1, ...
    'batchSize', 4, 'learningRate', 0.001, 'lrDownFreq', 3, 'momentum', 0.9, 'weightDecay', 0.1, 'compFeatsFrequency', 5, ...
    'nNegChoice', 30, 'nNegCap', 10, 'nNegCache', 10, ...
    'nEpoch', 20, ...
    'epochTestFrequency', 1, 'test0', true, ...
    'nTestSample', inf, 'nTestRankSample', 40, ...
    'saveFrequency', 15, 'doDraw', true, ...
    'useGPU', true, 'numThreads', 12, ...
    'computeBatchSize', 10, ...
    'sessionID', 'fb44',...
    'startEpoch', 11, ...
    'info', 'tiny test');
